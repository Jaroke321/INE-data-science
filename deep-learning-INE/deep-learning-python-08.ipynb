{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Layers\n",
    "\n",
    "In this notebook, we'll use the MNIST dataset to explore different optimizers and their parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the MNIST data functions\n",
    "# matplotlib for plotting\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start with the MNIST Dataset again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mnist.load_data() will automatically download the dataset if you don't have it\n",
    "(MNIST_train_X, MNIST_train_y), (MNIST_test_X, MNIST_test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit of preprocessing on the data before we can train (teach) our network\n",
    "\n",
    "For today, just ignore this.  Consider it a \"Necessary evil\". It's really not evil, but it is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_train_X = MNIST_train_X.reshape((60000, 28 * 28))\n",
    "MNIST_train_X = MNIST_train_X.astype('float32') / 255\n",
    "\n",
    "MNIST_test_X = MNIST_test_X.reshape((10000, 28 * 28))\n",
    "MNIST_test_X = MNIST_test_X.astype('float32') / 255\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "MNIST_train_y = to_categorical(MNIST_train_y)\n",
    "MNIST_test_y = to_categorical(MNIST_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Topology of the network\n",
    "\n",
    "OK! We are going to finally change this up.  Let's experiment with different amounts of layers.\n",
    "First we'll try more and less width (on a single layer). Then we'll try extra depth.\n",
    "Let's try a few values, `128, 512, 1024, 2048` for the width and see what happens.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.9359 - accuracy: 0.2503\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.5362 - accuracy: 0.4118\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.3917 - accuracy: 0.4850\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.2994 - accuracy: 0.5230\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.2279 - accuracy: 0.5527\n",
      "  1/313 [..............................] - ETA: 0s - loss: 0.9472 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0011s). Check your callbacks.\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.1717 - accuracy: 0.5759\n",
      "test_acc: 0.5759000182151794\n"
     ]
    }
   ],
   "source": [
    "network = models.Sequential() #we'll stick to sequential for this course\n",
    "\n",
    "# the first parameter of the layers.Dense() is the # of units. Which is how wide the layer is. Let's start with 128\n",
    "network.add(layers.Dense(2, activation='relu', input_shape=(784,)))  # Dense is the same as fully connected.\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',# change this parameter here.\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "network.fit(MNIST_train_X, MNIST_train_y, epochs=5, batch_size=128)\n",
    "\n",
    "\n",
    "test_loss, test_acc = network.evaluate(MNIST_test_X, MNIST_test_y)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record your results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5000 = 0.9815\n",
    "\n",
    "1024 = 0.9804\n",
    "\n",
    "128 = 0.9728\n",
    "\n",
    "12 = 0.9329\n",
    "\n",
    "6 = 0.8993\n",
    "\n",
    "2 = 0.5476"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can you draw any conclusions about the width?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More experiments, don't be shy!\n",
    "\n",
    "Let's also try something really small, like `5, 16` or somthing really large like `10000` what do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your answer here :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's adjust the depth\n",
    "\n",
    "We adjust the depth, by creating *more* layers.\n",
    "We always need one input layer, and one output layer. But we can add more in the middle.\n",
    "I'll add one below for you. Then you should try it with, `2,3, and 4` hidden layers.\n",
    "I'm not sure what the best amount of nodes per layer should be!  Let's try slowly reducing it as we go.\n",
    "\n",
    "`512 >> 256 >> 128 >> 64` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential() #we'll stick to sequential for this course\n",
    "\n",
    "#input layer\n",
    "network.add(layers.Dense(256, activation='relu', input_shape=(784,)))  # Dense is the same as fully connected.\n",
    "\n",
    "# let's add another layer -- keep the activation function as 'relu'\n",
    "network.add(layers.Dense(64, activation='relu'))\n",
    "#network.add(layers.Dense(32, activation='relu'))\n",
    "#network.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "#output layer\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 218,058\n",
      "Trainable params: 218,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.9180\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1115 - accuracy: 0.9664\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0742 - accuracy: 0.9771\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0545 - accuracy: 0.9826\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.9870\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0805 - accuracy: 0.9771\n",
      "test_acc: 0.9771000146865845\n"
     ]
    }
   ],
   "source": [
    "network.fit(MNIST_train_X, MNIST_train_y, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_acc = network.evaluate(MNIST_test_X, MNIST_test_y)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record your results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "512 >> 256 >> 128 >> 10:  0.9764\n",
    "\n",
    "12 >> 6 >> 3 >> 10 : 0.8815\n",
    "\n",
    "12 >> 6 >>3 >> 1 >> 10: \n",
    "\n",
    "6 >> 3 >> 10 : 0.347\n",
    "\n",
    "6 >> 128 >> 10 : 0.9144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions about depth in layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep experimenting.\n",
    "\n",
    "What happens if you invert the direction, make the layers get larger? `10 >> 50 >> 500 > output`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
